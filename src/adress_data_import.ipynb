{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# !pip install pypdf3\n",
    "# !pip install tabula-py\n",
    "# !pip install camelot-py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import camelot as camel\n",
    "from PyPDF3 import PdfFileReader \n",
    "from tabula import read_pdf \n",
    "# from tabulate import tabulate\n",
    "\n",
    "from my_modules import my_functions as mybib\n",
    "from my_modules import project_functions as pr\n",
    "\n",
    "# progress bar \n",
    "from tqdm import tqdm\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# https://www.youtube.com/watch?v=702lkQbZx50 - for tabula\n",
    "# https://stackoverflow.com/questions/45457054/tabula-extract-tables-by-area-coordinates - for tabula \n",
    "\n",
    "#FIXME: ADDRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/43259717/progress-bar-for-a-for-loop-in-python-script - progress bar\n",
    "# https://stackoverflow.com/questions/47021185/is-there-a-way-to-close-the-file-pdffilereader-opens - context manager \n",
    "# https://www.youtube.com/watch?v=OZo2HxoIOtw - open path as binary \n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_all_pages_from_pdf(path, file_name, counter, lenght):\n",
    "    with open(path, 'rb') as f:\n",
    "        # open path as binary / rb = read binary -> used for pdf files\n",
    "        counter += 1        \n",
    "        pdf = PdfFileReader(f)\n",
    "        last_page = pdf.getNumPages()\n",
    "        last_page += 1\n",
    "\n",
    "        # defining page range for import \n",
    "        [i for i in range(0, 15)]\n",
    "        page_range = [i for i in range(5, last_page)]\n",
    "        # print(page_range)\n",
    "\n",
    "        # prepare column name filler\n",
    "        column_names = [i for i in range(0, 14)]\n",
    "        # print(column_names)\n",
    "\n",
    "        # create empty dataframe\n",
    "        adress_data = pd.DataFrame(columns = column_names)\n",
    "        # display(adress_data)\n",
    "        \n",
    "        # extract district information \n",
    "        #TODO: nochmal pr√ºfen und vielleicht optimieren\n",
    "        district = [re.findall(r'(?<=adr_)(.*?)(?=_\\d{4}\\.pdf)', file_name)]\n",
    "        print(f'file {counter}/{lenght} - {district[0][0]}')\n",
    "        for page in tqdm(page_range):\n",
    "            \n",
    "            import_data = read_pdf(path, pages = page, encoding = 'ISO-8859-1', stream = True, area = [175, 33, 783, 520], guess = True, pandas_options={'header': None})\n",
    "            table_df = import_data[0]\n",
    "\n",
    "            \n",
    "            table_df = import_data[0]\n",
    "            columns_len = len(table_df.columns)\n",
    "\n",
    "            if columns_len < 14:\n",
    "                if table_df.iloc[:, 3].dtype in ['int64', 'int32', 'float64', 'float32']:\n",
    "                    table_df.insert(3, 'm1', np.nan)\n",
    "\n",
    "                if table_df.iloc[:, 6].dtype in ['int64', 'int32', 'float64', 'float32']:\n",
    "                    table_df.insert(5, 'm2', np.nan)\n",
    "                \n",
    "                \n",
    "                column_length = len(table_df.columns)\n",
    "\n",
    "                \n",
    "                if column_length < 14:\n",
    "                    table_df['m3'] = np.nan\n",
    "                    # display(table_df)\n",
    "                \n",
    "                \n",
    "                table_df.columns = column_names\n",
    "                table_df['14'] = str(district[0][0])\n",
    "                \n",
    "                adress_data = pd.concat([adress_data, table_df], ignore_index=True , axis=0)\n",
    "\n",
    "        return adress_data, district[0][0], counter\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_adress_data_by_year(year):\n",
    "    path = f'../data/input/berlin_adresses/{year}'\n",
    "    \n",
    "    list_of_files = os.listdir(path)\n",
    "    list_of_files\n",
    "    \n",
    "    length = len(list_of_files)\n",
    "    counter = 0 \n",
    "    \n",
    "    column_names = [i for i in range(0, 14)]\n",
    "    # print(len(column_names))\n",
    "    final_df = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "    print(f'Extracting data from files in {path}')\n",
    "    \n",
    "    for file_name in (list_of_files):\n",
    "        path = f'../data/input/berlin_adresses/{year}/{file_name}'\n",
    "        df, name, counter = extract_all_pages_from_pdf(path, file_name, counter, length)\n",
    "        \n",
    "        df.to_pickle(f'../data/output/temp_adress_data/{name}-{year}.csv', index = False)\n",
    "        \n",
    "        final_df = pd.concat([final_df, df], ignore_index=True , axis=0)\n",
    "        \n",
    "        # display(dataset.head(5))\n",
    "        # print(dataset.shape)\n",
    "    return final_df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe remote Jupyter Server contributed by the extension 'Jupyter' is no longer available. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time \n",
    "total_df = get_adress_data_by_year(2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_pickle(\"../data/output/temp_adress_data/address_data.pkl\")\n",
    "total_df.to_csv(\"../data/output/temp_adress_data/address_data.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
